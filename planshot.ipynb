{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPHN7PJgKOzb"
   },
   "source": [
    "# Interacting with CLIP\n",
    "\n",
    "This is a self-contained notebook that shows how to download and run CLIP models, calculate the similarity between arbitrary image and text inputs, and perform zero-shot image classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53N4k0pj_9qL"
   },
   "source": [
    "# Preparation for Colab\n",
    "\n",
    "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. The next cells will install the `clip` package and its dependencies, and check if PyTorch 1.7.1 or later is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BpdJkdBssk9",
    "outputId": "3d9059a1-7707-4456-8d53-ba36e3d5bbcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in /opt/anaconda3/lib/python3.12/site-packages (6.2.3)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.12/site-packages (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.4)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/anaconda3/lib/python3.12/site-packages (from ftfy) (0.2.13)\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/zx/46y7zv8x5gd6xfp0s16kr0w00000gp/T/pip-req-build-eqiknrg9\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/zx/46y7zv8x5gd6xfp0s16kr0w00000gp/T/pip-req-build-eqiknrg9\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /opt/anaconda3/lib/python3.12/site-packages (from clip==1.0) (6.2.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from clip==1.0) (23.2)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.12/site-packages (from clip==1.0) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from clip==1.0) (4.66.4)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from clip==1.0) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (from clip==1.0) (0.19.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/anaconda3/lib/python3.12/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->clip==1.0) (69.5.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision->clip==1.0) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->clip==1.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch->clip==1.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install ftfy regex tqdm\n",
    "! pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1hkDT38hSaP",
    "outputId": "0caecc2b-0811-4663-8eb7-ba1af247121a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFxgLV5HAEEw"
   },
   "source": [
    "# Loading the model\n",
    "\n",
    "`clip.available_models()` will list the names of available CLIP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLFS29hnhlY4",
    "outputId": "942301df-6204-4839-8050-9efac9066934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "\n",
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBRVTY9lbGm8",
    "outputId": "7d4e06e3-4d42-4e35-b1a6-bd390d4c0ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 151,277,313\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\")\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21slhZGCqANb"
   },
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "We resize the input images and center-crop them to conform with the image resolution that the model expects. Before doing so, we will normalize the pixel intensity using the dataset mean and standard deviation.\n",
    "\n",
    "The second return value from `clip.load()` contains a torchvision `Transform` that performs this preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6cpiIFHp9N6",
    "outputId": "dde02e3f-fa6d-4844-9043-c0d7ecbf7da3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    <function _convert_image_to_rgb at 0x144e79da0>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwSB5jZki3Cj"
   },
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "We use a case-insensitive tokenizer, which can be invoked using `clip.tokenize()`. By default, the outputs are padded to become 77 tokens long, which is what the CLIP models expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGom156-i2kL",
    "outputId": "5cf8b35d-5984-42d7-cf7b-aa4651ae37f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,   637,  1237,  2097, 49407,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.tokenize(\"one two three\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W8ARJVqBJXs"
   },
   "source": [
    "# Setting up input images and texts\n",
    "\n",
    "We are going to feed 8 example images and their textual descriptions to the model, and compare the similarity between the corresponding features.\n",
    "\n",
    "The tokenizer is case-insensitive, and we can freely give any suitable textual descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tMc1AXzBlhzm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEVKsji6WOIX"
   },
   "source": [
    "## Building features\n",
    "\n",
    "We normalize the images, tokenize each text input, and run the forward pass of the model to get the image and text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MfirHzM2hvDe"
   },
   "outputs": [],
   "source": [
    "def loadImage(url, rows=5, cols=5):\n",
    "  original_images = []\n",
    "  urllib.request.urlretrieve(\n",
    "    url,\n",
    "    \"img.gif\")\n",
    "  im = Image.open(\"img.gif\")\n",
    "  try:\n",
    "    while 1:\n",
    "      im.seek(im.tell()+1)\n",
    "      original_images.append(im.convert(\"RGB\"))\n",
    "  except EOFError:\n",
    "    pass\n",
    "\n",
    "  print(len(original_images))\n",
    "\n",
    "  processed_images = []\n",
    "\n",
    "  for image in original_images:\n",
    "    processed_images.append(preprocess(image))\n",
    "\n",
    "  plt.figure(figsize=(20, 10))\n",
    "  start = 0\n",
    "  for i in range(rows*cols):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(original_images[start+i])\n",
    "    plt.axis('off')\n",
    "    #plt.title(str(start+i))\n",
    "  plt.tight_layout()\n",
    "  plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "  return original_images, processed_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Files (Data Collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# print(sorted(os.listdir(\"./gifs\"), key = lambda x: int(x.split(\".\")[0]))[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_files_in_folder(folder_path, start_value, file_extension):\n",
    "    files = sorted(os.listdir(folder_path))\n",
    "    for i, filename in enumerate(files):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        new_name = f\"{start_value + i}.{file_extension}\"\n",
    "        old_file = os.path.join(folder_path, filename)\n",
    "        new_file = os.path.join(folder_path, new_name)\n",
    "        os.rename(old_file, new_file)\n",
    "        print(f\"Renamed {filename} to {new_name}\")\n",
    "\n",
    "# Example usage:\n",
    "# folder_path = '../GIFS'\n",
    "# start_value = int(sorted(os.listdir(\"./gifs\"), key = lambda x: int(x.split(\".\")[0]))[-1].split(\".\")[0]) + 1\n",
    "# file_extension = 'gif'\n",
    "# rename_files_in_folder(folder_path, start_value, file_extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadImageLocal(local_path, rows=5, cols=5):\n",
    "    original_images = []\n",
    "\n",
    "    im = Image.open(local_path)\n",
    "    \n",
    "    try:\n",
    "        im.seek(im.tell())\n",
    "        original_images.append(im.convert(\"RGB\"))\n",
    "        while 1:\n",
    "            im.seek(im.tell()+1)\n",
    "            original_images.append(im.convert(\"RGB\"))\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "    print(len(original_images))\n",
    "\n",
    "    processed_images = []\n",
    "\n",
    "    for image in original_images:\n",
    "        processed_images.append(preprocess(image))\n",
    "\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # start = 0\n",
    "    # for i in range(rows*cols):\n",
    "    #     plt.subplot(rows, cols, i+1)\n",
    "    #     plt.imshow(original_images[start+i])\n",
    "    #     plt.axis('off')\n",
    "    #     plt.title(str(start+i))\n",
    "    # plt.tight_layout()\n",
    "    # plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "    return original_images, processed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "a,b=loadImageLocal(\"gifs/14.gif\", 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "HBgCanxi8JKw"
   },
   "outputs": [],
   "source": [
    "def findMatch(original_images, processed_images, texts, show_output=False):\n",
    "    t1 = time.perf_counter()\n",
    "    image_input = torch.tensor(np.stack(processed_images))\n",
    "    text_tokens = clip.tokenize([\"This is \" + desc for desc in texts])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input).float()\n",
    "        text_features = model.encode_text(text_tokens).float()\n",
    "\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
    "    t2 = time.perf_counter()\n",
    "    print('time (sec) taken to run:', t2 - t1)\n",
    "\n",
    "    # print(similarity)\n",
    "    if show_output:\n",
    "        plt.figure(figsize=(18, 6 * len(texts)))\n",
    "    \n",
    "    results = []\n",
    "    for i, text in enumerate(texts):\n",
    "        if show_output:\n",
    "            plt.subplot(len(texts), 2, 1 + 2 * i)\n",
    "            plt.plot(range(len(similarity[i])), similarity[i])\n",
    "        results.append(np.argmax(similarity[i]))\n",
    "        if show_output:\n",
    "            plt.subplot(len(texts), 2, 2 + 2 * i)\n",
    "            plt.imshow(original_images[np.argmax(similarity[i])])\n",
    "            plt.title(text, fontdict={'fontsize': 40})\n",
    "    if show_output:\n",
    "        plt.tight_layout()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "\n",
    "def showFrames(path):\n",
    "    gif_path = path\n",
    "    gif = Image.open(gif_path)\n",
    "    \n",
    "    root = tk.Tk()\n",
    "    root.title(\"Picking Best Frame\")\n",
    "    \n",
    "    frame_number = 0\n",
    "    frames = []\n",
    "    while True:\n",
    "        try:\n",
    "            gif.seek(frame_number)\n",
    "            frame = gif.copy()\n",
    "            frames.append(frame)\n",
    "            frame_number += 1\n",
    "        except EOFError:\n",
    "            break\n",
    "    \n",
    "    def display_frame(index):\n",
    "        frame_label.config(text=f\"Frame {index}\")\n",
    "        img = ImageTk.PhotoImage(frames[index])\n",
    "        frame_canvas.create_image(0, 0, anchor=tk.NW, image=img)\n",
    "        frame_canvas.image = img\n",
    "    \n",
    "    frame_label = tk.Label(root, text=\"Frame 0\", font=('Typo Round', 14))\n",
    "    frame_label.pack()\n",
    "    \n",
    "    frame_canvas = tk.Canvas(root, width=frames[0].width, height=frames[0].height)\n",
    "    frame_canvas.pack()\n",
    "    \n",
    "    display_frame(0)\n",
    "    \n",
    "    def next_frame(event):\n",
    "        current_frame = int(frame_label.cget(\"text\").split()[1])\n",
    "        next_index = (current_frame + 1) % len(frames)\n",
    "        display_frame(next_index)\n",
    "    def prev_frame(event):\n",
    "        current_frame = int(frame_label.cget(\"text\").split()[1])\n",
    "        next_index = (current_frame - 1) % len(frames)\n",
    "        display_frame(next_index)\n",
    "    \n",
    "    root.bind('<Right>', next_frame)\n",
    "    root.bind('<Left>', prev_frame)\n",
    "    \n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2bGFUKNPhoAv",
    "outputId": "44177d64-d701-453d-b1a7-02f295c0d3a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "time (sec) taken to run: 0.3163117499789223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GIF = 'gifs/87.gif'\n",
    "texts = [\"ball hits face\"]\n",
    "orig_imgs, proc_imgs = loadImageLocal(GIF)\n",
    "findMatch(orig_imgs, proc_imgs, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from `photo_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Correct Frame</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Gifs Completed</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>woman falls down</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>woman falls down</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>guy falls down onto couch</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>person falls down</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>guy falls down</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                Description  Correct Frame  Unnamed: 3  Unnamed: 4  \\\n",
       "0  1.0           woman falls down           19.0         NaN         NaN   \n",
       "1  2.0           woman falls down            9.0         NaN         NaN   \n",
       "2  3.0  guy falls down onto couch           28.0         NaN         NaN   \n",
       "3  4.0          person falls down           14.0         NaN         NaN   \n",
       "4  5.0             guy falls down           10.0         NaN         NaN   \n",
       "\n",
       "  Gifs Completed  Unnamed: 6 Unnamed: 7  Frequency  \n",
       "0              1         1.0       True          2  \n",
       "1              2         2.0       True          1  \n",
       "2              3         3.0       True          2  \n",
       "3              4         4.0       True          1  \n",
       "4              5         5.0       True          1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "photo_data_csv = pd.read_csv(\"photo_data.csv\")\n",
    "photo_data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gifs/1.png', 'woman falls down', 19),\n",
       " ('gifs/2.png', 'woman falls down', 9),\n",
       " ('gifs/3.png', 'guy falls down onto couch', 28),\n",
       " ('gifs/4.png', 'person falls down', 14),\n",
       " ('gifs/5.png', 'guy falls down', 10),\n",
       " ('gifs/6.png', 'guy falls onto ground', 29),\n",
       " ('gifs/7.png', 'a small kid falls down', 22),\n",
       " ('gifs/8.png', 'a dog catching a frisbee in mouth', 67),\n",
       " ('gifs/8.png', 'a dog catch frisbee in mouth', 67),\n",
       " ('gifs/8.png', 'a dog with frisbee in mouth', 67),\n",
       " ('gifs/8.png', 'a dog catching a frisbee in its mouth', 67),\n",
       " ('gifs/11.png', 'guy throws tennis racket', 35),\n",
       " ('gifs/11.png', 'guy throws tennis racquet', 35),\n",
       " ('gifs/11.png', 'guy throwing tennis racquet', 35),\n",
       " ('gifs/11.png', 'guy throwing tennis racket', 35),\n",
       " ('gifs/12.png', 'guy hitting tennis ball with racket', 10),\n",
       " ('gifs/12.png', 'guy hits tennis ball with racket', 10),\n",
       " ('gifs/12.png', 'tennis racket hits ball', 10),\n",
       " ('gifs/12.png', 'guy hits ball with tennis racket', 10),\n",
       " ('gifs/13.png', 'guy falls down', 10),\n",
       " ('gifs/14.png', 'tennis ball hits racket', 20),\n",
       " ('gifs/14.png', \"tennis ball hits guy's racket\", 20),\n",
       " ('gifs/14.png', \"tennis ball hitting guy's racket\", 20),\n",
       " ('gifs/15.png', 'tennis ball hitting face', 4),\n",
       " ('gifs/13.png', 'man fall onto ground', 11),\n",
       " ('gifs/15.png', 'tennis ball hits face', 4),\n",
       " ('gifs/16.png', 'tennis ball hits racket', 13),\n",
       " ('gifs/7.png', 'small kid falls down', 22),\n",
       " ('gifs/1.png', 'a woman falls down', 19),\n",
       " ('gifs/16.png', 'tennis ball hitting racket', 13),\n",
       " ('gifs/16.png', 'tennis ball bounces off racket', 13),\n",
       " ('gifs/3.png', 'guy face-plants into couch', 28),\n",
       " ('gifs/17.png', 'guy hitting tennis ball with racket', 38),\n",
       " ('gifs/17.png', 'guy hits tennis ball with racket', 38),\n",
       " ('gifs/17.png', 'guy hits tennis ball with racket', 38),\n",
       " ('gifs/17.png', 'guy hits tennis ball with racquet', 38),\n",
       " ('gifs/17.png', 'tennis racket hits ball', 38),\n",
       " ('gifs/18.png', 'a dog catching a frisbee in air', 13),\n",
       " ('gifs/18.png', 'a dog catching a carrot in air', 13),\n",
       " ('gifs/18.png', 'a dog catching frisbee in air', 13),\n",
       " ('gifs/18.png', 'dog catching frisbee in air', 13),\n",
       " ('gifs/18.png', 'dog catching a carrot in air', 13),\n",
       " ('gifs/18.png', 'dog catching a carrot midair', 13),\n",
       " ('gifs/18.png', 'a dog catching frisbee midair', 13),\n",
       " ('gifs/19.png', 'tennis racket hitting ball', 46),\n",
       " ('gifs/19.png', 'guy hits tennis ball with racket', 46),\n",
       " ('gifs/19.png', 'tennis ball gets hit by racket', 46),\n",
       " ('gifs/19.png', 'tennis ball impacts with racket', 46),\n",
       " ('gifs/20.png', 'dog with frisbeee in mouth midair', 1),\n",
       " ('gifs/20.png', 'dog catching frisbee midair', 2),\n",
       " ('gifs/20.png', 'a dog catching a frisbee in midair', 2),\n",
       " ('gifs/21.png', 'fish eating fish', 8),\n",
       " ('gifs/21.png', 'a fish eating another fish', 8),\n",
       " ('gifs/21.png', 'fish gets eaten by another fish', 8),\n",
       " ('gifs/21.png', 'fish eats another fish', 8),\n",
       " ('gifs/22.png', 'baseball bat hitting ball', 40),\n",
       " ('gifs/22.png', 'baseball hits baseball bat', 40),\n",
       " ('gifs/22.png', 'baseball hits stick', 40),\n",
       " ('gifs/22.png', 'baseball impacts bat', 40),\n",
       " ('gifs/22.png', 'baseball hitting baseball bat', 40),\n",
       " ('gifs/25.png', 'a squirrel shaking its ears', 28),\n",
       " ('gifs/25.png', 'a squirrel shaking ears', 26),\n",
       " ('gifs/35.png', 'a cat peeking out of a toilet', 0),\n",
       " ('gifs/26.png', 'dog jumping', 6),\n",
       " ('gifs/26.png', 'dog in the air', 6),\n",
       " ('gifs/27.png', 'fox jumping', 12),\n",
       " ('gifs/27.png', 'fox in the air', 12),\n",
       " ('gifs/28.png', 'cat flying', 26),\n",
       " ('gifs/28.png', 'cat jumping', 26),\n",
       " ('gifs/29.png', 'cat jumps on top of dog', 15),\n",
       " ('gifs/29.png', 'a cat on top of a dog', 15),\n",
       " ('gifs/30.png', 'a panda jumps onto another panda', 9),\n",
       " ('gifs/38.png', 'a cat biting corn', 13),\n",
       " ('gifs/38.png', 'a cat biting into corn', 13),\n",
       " ('gifs/30.png', 'panda hits panda', 9),\n",
       " ('gifs/39.png', 'a cat jumping', 16),\n",
       " ('gifs/39.png', 'a cat jumping across', 16),\n",
       " ('gifs/31.png', 'goat jumping', 6),\n",
       " ('gifs/39.png', 'a cat jumping in air', 16),\n",
       " ('gifs/39.png', 'a cat jumps in air', 16),\n",
       " ('gifs/9.png', 'a dog catching a frisbee in air', 19),\n",
       " ('gifs/23.png', 'small kid falls on top of small kid', 51),\n",
       " ('gifs/9.png', 'a dog catching a frisbee in midair', 19),\n",
       " ('gifs/9.png', 'a dog catching a frisbee midair', 19),\n",
       " ('gifs/9.png', 'dog catching frisbee in air', 19),\n",
       " ('gifs/10.png', 'a dog catching a frisbee in midair', 40),\n",
       " ('gifs/10.png', 'a dog catching a frisbee midair', 40),\n",
       " ('gifs/10.png', 'dog catching frisbee in air', 40),\n",
       " ('gifs/10.png', 'a dog with frisbee in mouth', 40),\n",
       " ('gifs/24.png', 'a dog catching a frisbee in air', 89),\n",
       " ('gifs/23.png', 'small kid knocks over small kid on ground', 51),\n",
       " ('gifs/24.png', 'a dog catching a frisbee midair', 89),\n",
       " ('gifs/24.png', 'dog catching frisbee in air', 89),\n",
       " ('gifs/24.png', 'a dog with frisbee in mouth', 89),\n",
       " ('gifs/33.png', 'a rabbit hops', 3),\n",
       " ('gifs/32.png', 'cat jumps', 3),\n",
       " ('gifs/34.png', 'a duck lands', 12),\n",
       " ('gifs/34.png', 'a duck lands on ground', 12),\n",
       " ('gifs/36.png', 'a horse jumping over a hurdle', 16),\n",
       " ('gifs/37.png', 'goat kicks black goat', 13),\n",
       " ('gifs/36.png', 'a horse jumping across a hurdle', 16),\n",
       " ('gifs/36.png', 'a horse jumping across a hurdle', 16),\n",
       " ('gifs/36.png', 'a horse jumping over a hurdle in midair', 16),\n",
       " ('gifs/37.png', 'black goat falls over', 16),\n",
       " ('gifs/63.png', 'guy jumping over buildings', 52),\n",
       " ('gifs/63.png', 'guy jumping across buildings', 52),\n",
       " ('gifs/40.png', 'dog jumps through hoop', 19),\n",
       " ('gifs/42.png', 'goat jumps', 14),\n",
       " ('gifs/42.png', 'goat jumps through air', 14),\n",
       " ('gifs/41.png', 'red ball hits kid', 61),\n",
       " ('gifs/42.png', 'goat jumping in air', 14),\n",
       " ('gifs/42.png', 'goat jumps in midair', 14),\n",
       " ('gifs/41.png', 'kid gets hit in the face with ball', 61),\n",
       " ('gifs/43.png', 'dog jumping through hoop', 2),\n",
       " ('gifs/43.png', 'dog jumps through hoop', 2),\n",
       " ('gifs/45.png', 'cat jumps', 12),\n",
       " ('gifs/44.png', 'dog jumps through hoop', 19),\n",
       " ('gifs/44.png', 'dog jumping', 19),\n",
       " ('gifs/46.png', 'dolphin jumping', 3),\n",
       " ('gifs/46.png', 'dolphin jumps through hoop', 3),\n",
       " ('gifs/45.png', 'cat jumping in air', 12),\n",
       " ('gifs/45.png', 'cat jumps in air', 12),\n",
       " ('gifs/45.png', 'cat jumping', 12),\n",
       " ('gifs/48.png', 'horse jumps', 10),\n",
       " ('gifs/47.png', 'dog catches frisbee in mouth', 20),\n",
       " ('gifs/47.png', 'dog jumping with frisbee midair', 20),\n",
       " ('gifs/48.png', 'horse jumping', 10),\n",
       " ('gifs/49.png', 'guy jumps backward', 40),\n",
       " ('gifs/49.png', 'guy jumps through hoop', 40),\n",
       " ('gifs/49.png', 'man jumping', 40),\n",
       " ('gifs/50.png', 'pig jumps through hoop', 5),\n",
       " ('gifs/51.png', 'horse jumps over hurdle', 15),\n",
       " ('gifs/52.png', 'horse jumps over hurdle', 4),\n",
       " ('gifs/51.png', 'horse jumping over hurdle', 15),\n",
       " ('gifs/52.png', 'horse jumps', 4),\n",
       " ('gifs/51.png', 'horse jumping in air', 11),\n",
       " ('gifs/53.png', 'horse jumps over hurdle', 18),\n",
       " ('gifs/53.png', 'horse jumping over hurdle', 26),\n",
       " ('gifs/54.png', 'horse jumping over hurdle', 11),\n",
       " ('gifs/53.png', 'horse jumping across hurdle', 26),\n",
       " ('gifs/54.png', 'horse jumps', 11),\n",
       " ('gifs/53.png', 'a horse jumping across hurdle', 26),\n",
       " ('gifs/55.png', 'a horse jumping over a hurdle', 6),\n",
       " ('gifs/56.png', 'guy does thumbs up', 25),\n",
       " ('gifs/56.png', 'kid thumbs up', 25),\n",
       " ('gifs/55.png', 'a horse jumping over hurdle', 6),\n",
       " ('gifs/55.png', 'horse jumping over a hurdle', 6),\n",
       " ('gifs/55.png', 'a horse jumping over the hurdle', 6),\n",
       " ('gifs/55.png', 'horse jumping across the hurdle', 6),\n",
       " ('gifs/55.png', 'a horse jumps', 6),\n",
       " ('gifs/55.png', 'horse jumping over a hurdle', 6),\n",
       " ('gifs/57.png', 'horse jumps over hurdle', 11),\n",
       " ('gifs/58.png', 'guy landing in dirt', 27),\n",
       " ('gifs/57.png', 'a horse jumping', 11),\n",
       " ('gifs/57.png', 'horse jumps', 11),\n",
       " ('gifs/59.png', 'glass shatters', 5),\n",
       " ('gifs/59.png', 'glass breaks', 5),\n",
       " ('gifs/58.png', 'guy lands on ground', 26),\n",
       " ('gifs/58.png', 'guy lands in dirt', 27),\n",
       " ('gifs/58.png', 'face-plant in dirt', 27),\n",
       " ('gifs/60.png', 'guy claps', 0),\n",
       " ('gifs/60.png', \"man's hands touch each other physically\", 0),\n",
       " ('gifs/61.png', 'glass shattering', 40),\n",
       " ('gifs/61.png', 'glass shatters', 40),\n",
       " ('gifs/62.png', 'glass shattering', 14),\n",
       " ('gifs/64.png', 'guy showing thumbs-up', 6),\n",
       " ('gifs/64.png', 'guy doing thumbs-up', 6),\n",
       " ('gifs/65.png', 'baseball hits bat', 3),\n",
       " ('gifs/65.png', 'guy hits baseball with bat', 3),\n",
       " ('gifs/65.png', 'bat touches baseball', 3),\n",
       " ('gifs/67.png', 'baseball hits bat', 38),\n",
       " ('gifs/67.png', 'guy hits baseball with bat', 38),\n",
       " ('gifs/67.png', 'bat touches baseball', 38),\n",
       " ('gifs/66.png', 'guy kicks soccer ball with foot', 7),\n",
       " ('gifs/66.png', 'guy kicking soccer ball', 7),\n",
       " ('gifs/66.png', 'guy kicking soccer ball using foot', 7),\n",
       " ('gifs/66.png', 'dude kicks soccer ball', 7),\n",
       " ('gifs/66.png', 'guy boots soccer ball', 7),\n",
       " ('gifs/66.png', 'dude kicking soccer ball', 7),\n",
       " ('gifs/68.png', 'baseball hits bat', 33),\n",
       " ('gifs/68.png', 'guy hits baseball with bat', 33),\n",
       " ('gifs/68.png', 'bat touches baseball', 33),\n",
       " ('gifs/70.png', 'baseball hits bat', 52),\n",
       " ('gifs/70.png', 'guy hits baseball with bat', 52),\n",
       " ('gifs/70.png', 'bat touches baseball', 52),\n",
       " ('gifs/71.png', 'baseball hits bat', 33),\n",
       " ('gifs/71.png', 'guy hits baseball with bat', 33),\n",
       " ('gifs/71.png', 'bat touches baseball', 33),\n",
       " ('gifs/69.png', 'guy hitting baseball with bat', 45),\n",
       " ('gifs/69.png', 'baseball hits bat', 45),\n",
       " ('gifs/69.png', 'baseball impacts baseball bat', 45),\n",
       " ('gifs/69.png', 'guy hits baseball with bat', 45),\n",
       " ('gifs/69.png', 'baseball hitting bat', 45),\n",
       " ('gifs/72.png', 'guy hitting baseball with baseball bat', 17),\n",
       " ('gifs/72.png', 'dude hits baseball with bat', 17),\n",
       " ('gifs/72.png', 'baseball impacts baseball bat', 17),\n",
       " ('gifs/72.png', 'guy hits baseball with bat', 17),\n",
       " ('gifs/72.png', 'baseball hitting baseball bat', 17),\n",
       " ('gifs/69.png', 'dude hits baseball using bat', 45),\n",
       " ('gifs/74.png', 'basketball hits face', 32),\n",
       " ('gifs/74.png', 'basketball hits guy', 32),\n",
       " ('gifs/74.png', \"basketball hits guy's face\", 32),\n",
       " ('gifs/74.png', \"basketball hitting dude's face\", 32),\n",
       " ('gifs/73.png', 'guy hitting baseball with baseball bat', 15),\n",
       " ('gifs/73.png', 'dude hits baseball with bat', 15),\n",
       " ('gifs/73.png', 'baseball impacts baseball bat', 15),\n",
       " ('gifs/73.png', 'guy hits baseball with bat', 15),\n",
       " ('gifs/73.png', 'baseball hitting baseball bat', 15),\n",
       " ('gifs/75.png', 'guy hitting baseball with baseball bat', 20),\n",
       " ('gifs/75.png', 'dude hits baseball with bat', 20),\n",
       " ('gifs/75.png', 'baseball impacts baseball bat', 20),\n",
       " ('gifs/75.png', 'guy hits baseball with bat', 20),\n",
       " ('gifs/75.png', 'baseball hitting baseball bat', 20),\n",
       " ('gifs/76.png', 'guy hitting baseball with baseball bat', 6),\n",
       " ('gifs/76.png', 'dude hits baseball with bat', 6),\n",
       " ('gifs/76.png', 'baseball impacts baseball bat', 6),\n",
       " ('gifs/76.png', 'guy hits baseball with bat', 6),\n",
       " ('gifs/76.png', 'baseball hitting baseball bat', 6),\n",
       " ('gifs/77.png', 'guy hitting baseball with baseball bat', 7),\n",
       " ('gifs/77.png', 'dude hits baseball with bat', 7),\n",
       " ('gifs/77.png', 'baseball impacts baseball bat', 7),\n",
       " ('gifs/77.png', 'guy hits baseball with bat', 7),\n",
       " ('gifs/77.png', 'baseball hitting baseball bat', 7),\n",
       " ('gifs/79.png', \"ball hits guy's head\", 2),\n",
       " ('gifs/79.png', 'guy is hit by basketball', 2),\n",
       " ('gifs/79.png', 'basketball bounces off side of head', 2),\n",
       " ('gifs/78.png', 'guy hitting baseball with baseball bat', 26),\n",
       " ('gifs/78.png', 'dude hits baseball with bat', 26),\n",
       " ('gifs/78.png', 'baseball impacts baseball bat', 26),\n",
       " ('gifs/78.png', 'guy hits baseball with bat', 26),\n",
       " ('gifs/78.png', 'baseball hitting baseball bat', 26),\n",
       " ('gifs/78.png', 'guy hitting baseball with bat', 26),\n",
       " ('gifs/80.png', 'guy hitting baseball with baseball bat', 34),\n",
       " ('gifs/80.png', 'dude hits baseball with bat', 34),\n",
       " ('gifs/80.png', 'baseball impacts baseball bat', 34),\n",
       " ('gifs/80.png', 'guy hits baseball with bat', 34),\n",
       " ('gifs/80.png', 'baseball hitting baseball bat', 34),\n",
       " ('gifs/80.png', 'guy hitting baseball with bat', 34),\n",
       " ('gifs/82.png', 'guy hitting baseball with baseball bat', 22),\n",
       " ('gifs/82.png', 'dude hits baseball with bat', 22),\n",
       " ('gifs/82.png', 'baseball impacts baseball bat', 22),\n",
       " ('gifs/82.png', 'guy hits baseball with bat', 22),\n",
       " ('gifs/82.png', 'baseball hitting baseball bat', 22),\n",
       " ('gifs/81.png', 'guy hitting baseball with baseball bat', 62),\n",
       " ('gifs/81.png', 'dude hits baseball with bat', 62),\n",
       " ('gifs/81.png', 'baseball impacts baseball bat', 62),\n",
       " ('gifs/81.png', 'guy hits baseball with bat', 62),\n",
       " ('gifs/81.png', 'baseball hitting baseball bat', 62),\n",
       " ('gifs/81.png', 'guy hitting baseball with bat', 62),\n",
       " ('gifs/83.png', 'soccer ball hits guy in face', 21),\n",
       " ('gifs/83.png', \"soccer ball hits guy's face\", 21),\n",
       " ('gifs/83.png', 'soccer ball hitting face', 21),\n",
       " ('gifs/83.png', \"soccer ball hitting dude's face\", 21),\n",
       " ('gifs/83.png', 'soccer ball hitting dude in face', 21),\n",
       " ('gifs/83.png', 'soccer ball impacting face', 21),\n",
       " ('gifs/84.png', 'guy hitting baseball with baseball bat', 20),\n",
       " ('gifs/84.png', 'dude hits baseball with bat', 20),\n",
       " ('gifs/84.png', 'baseball impacts baseball bat', 20),\n",
       " ('gifs/84.png', 'guy hits baseball with bat', 20),\n",
       " ('gifs/84.png', 'baseball hitting baseball bat', 20),\n",
       " ('gifs/85.png', 'guy hitting baseball with baseball bat', 42),\n",
       " ('gifs/85.png', 'dude hits baseball with bat', 42),\n",
       " ('gifs/85.png', 'baseball impacts baseball bat', 42),\n",
       " ('gifs/85.png', 'guy hits baseball with bat', 42),\n",
       " ('gifs/85.png', 'baseball hitting baseball bat', 42),\n",
       " ('gifs/85.png', 'guy hitting baseball with bat', 42),\n",
       " ('gifs/85.png', 'baseball impacting baseball bat', 42),\n",
       " ('gifs/86.png', 'ball hits face', 4),\n",
       " ('gifs/86.png', 'ball hitting face', 4),\n",
       " ('gifs/87.png', \"ball hits guy's head\", 2),\n",
       " ('gifs/87.png', 'guy is hit by basketball', 2),\n",
       " ('gifs/87.png', 'basketball bounces off side of head', 2)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labeled_data = photo_data_csv.iloc[:, :3]\n",
    "\n",
    "unfiltered_data_triples = list(all_labeled_data.itertuples(index=False, name=None))\n",
    "\n",
    "labeled_data_float = list(filter(lambda x: not math.isnan(x[0]), unfiltered_data_triples))\n",
    "\n",
    "labeled_data = list(map(lambda x: (f'gifs/{int(x[0])}.png', x[1], int(x[2])), labeled_data_float))\n",
    "\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 11.0,\n",
       " 11.0,\n",
       " 11.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 12.0,\n",
       " 12.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 13.0,\n",
       " 15.0,\n",
       " 16.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 16.0,\n",
       " 16.0,\n",
       " 3.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 20.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 21.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 22.0,\n",
       " 25.0,\n",
       " 25.0,\n",
       " 35.0,\n",
       " 26.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 29.0,\n",
       " 30.0,\n",
       " 38.0,\n",
       " 38.0,\n",
       " 30.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 31.0,\n",
       " 39.0,\n",
       " 39.0,\n",
       " 9.0,\n",
       " 23.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 10.0,\n",
       " 24.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 24.0,\n",
       " 33.0,\n",
       " 32.0,\n",
       " 34.0,\n",
       " 34.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 63.0,\n",
       " 63.0,\n",
       " 40.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 41.0,\n",
       " 42.0,\n",
       " 42.0,\n",
       " 41.0,\n",
       " 43.0,\n",
       " 43.0,\n",
       " 45.0,\n",
       " 44.0,\n",
       " 44.0,\n",
       " 46.0,\n",
       " 46.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 45.0,\n",
       " 48.0,\n",
       " 47.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 49.0,\n",
       " 50.0,\n",
       " 51.0,\n",
       " 52.0,\n",
       " 51.0,\n",
       " 52.0,\n",
       " 51.0,\n",
       " 53.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 53.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " 56.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 55.0,\n",
       " 57.0,\n",
       " 58.0,\n",
       " 57.0,\n",
       " 57.0,\n",
       " 59.0,\n",
       " 59.0,\n",
       " 58.0,\n",
       " 58.0,\n",
       " 58.0,\n",
       " 60.0,\n",
       " 60.0,\n",
       " 61.0,\n",
       " 61.0,\n",
       " 62.0,\n",
       " 64.0,\n",
       " 64.0,\n",
       " 65.0,\n",
       " 65.0,\n",
       " 65.0,\n",
       " 67.0,\n",
       " 67.0,\n",
       " 67.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 66.0,\n",
       " 68.0,\n",
       " 68.0,\n",
       " 68.0,\n",
       " 70.0,\n",
       " 70.0,\n",
       " 70.0,\n",
       " 71.0,\n",
       " 71.0,\n",
       " 71.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 69.0,\n",
       " 72.0,\n",
       " 72.0,\n",
       " 72.0,\n",
       " 72.0,\n",
       " 72.0,\n",
       " 69.0,\n",
       " 74.0,\n",
       " 74.0,\n",
       " 74.0,\n",
       " 74.0,\n",
       " 73.0,\n",
       " 73.0,\n",
       " 73.0,\n",
       " 73.0,\n",
       " 73.0,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 76.0,\n",
       " 76.0,\n",
       " 76.0,\n",
       " 76.0,\n",
       " 76.0,\n",
       " 77.0,\n",
       " 77.0,\n",
       " 77.0,\n",
       " 77.0,\n",
       " 77.0,\n",
       " 79.0,\n",
       " 79.0,\n",
       " 79.0,\n",
       " 78.0,\n",
       " 78.0,\n",
       " 78.0,\n",
       " 78.0,\n",
       " 78.0,\n",
       " 78.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 82.0,\n",
       " 82.0,\n",
       " 82.0,\n",
       " 82.0,\n",
       " 82.0,\n",
       " 81.0,\n",
       " 81.0,\n",
       " 81.0,\n",
       " 81.0,\n",
       " 81.0,\n",
       " 81.0,\n",
       " 83.0,\n",
       " 83.0,\n",
       " 83.0,\n",
       " 83.0,\n",
       " 83.0,\n",
       " 83.0,\n",
       " 84.0,\n",
       " 84.0,\n",
       " 84.0,\n",
       " 84.0,\n",
       " 84.0,\n",
       " 85.0,\n",
       " 85.0,\n",
       " 85.0,\n",
       " 85.0,\n",
       " 85.0,\n",
       " 85.0,\n",
       " 85.0,\n",
       " 86.0,\n",
       " 86.0,\n",
       " 87.0,\n",
       " 87.0,\n",
       " 87.0]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0, 1.0, 3.0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x != ,photo_data_csv['Id'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
